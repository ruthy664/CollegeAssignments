{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Similar to the Classwork 4 notebook, read in the `Iris.csv` data set. However, this time take only the 100 data points with a species label of either 1 or 2. Reset those labels to 1 and -1.\n",
    " \n",
    "- Next, run `90` steps in the Perceptron algorithm, storing your resulting $W$ vector. Then run `100` steps and store that vector. Then run `500` steps and store that vector. \n",
    "This data is not linearly separable. In each of the three cases, what percentage of the data is correctly labeled by the resulting half-space model? Does more steps produce a more accurate half-space model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From pervious classwork \n",
    "def Perceptron_Algorithm(x,Y,max_iter): # x is n by d, y is 1d array\n",
    "    X = np.hstack((x, np.ones((x.shape[0],1))))\n",
    "    W = np.zeros(x.shape[1]+1)\n",
    "    products = Y*(X@W)\n",
    "    iter = 0\n",
    "    while iter < max_iter:\n",
    "        try:\n",
    "            i = np.where(products <= 0)[0][0]\n",
    "            W += Y[i]*X[i]\n",
    "            products = Y*(X@W)\n",
    "            iter += 1\n",
    "        except IndexError:\n",
    "            break\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W for 90: [ 33.1   8.4 -41.3 -34.4   0. ] W for 100: [ 35.2  10.  -44.8 -36.6   0. ] W for 500: [  80.2  165.9 -109.3 -409.   328. ]\n",
      "percentage for 90 iterations: 25 %; percentage for 100 iterations: 24 %; percentage for 500 iterations: 64 %.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the data set \n",
    "iris = pd.read_csv(\"Iris.csv\")\n",
    "\n",
    "# Use only the rows where the last collumn is 1 or 2\n",
    "data = iris[(iris[\"species\"]==1)|(iris[\"species\"]==2)]\n",
    "# Set the last collumn to -1 if the value is 2; 1 is already 1\n",
    "data.loc[data[\"species\"]==2,\"species\"]=-1\n",
    "\n",
    "# Create the x and y arrays\n",
    "x = data[[\"x0\",\"x1\",\"x2\",\"x3\"]].values\n",
    "y = data[\"species\"].values\n",
    "\n",
    "# Make the array of W arrays for each part of the perceptron algorithm\n",
    "W = [[],[],[]]\n",
    "W[0] = Perceptron_Algorithm(x,y,90)\n",
    "W[1] = Perceptron_Algorithm(x,y,100)\n",
    "W[2] = Perceptron_Algorithm(x,y,500)\n",
    "print(\"W for 90:\",W[0],\"W for 100:\",W[1],\"W for 500:\",W[2])\n",
    "\n",
    "# Get X with the 1s included\n",
    "X = np.hstack((x, np.ones((x.shape[0],1))))\n",
    "\n",
    "# find the dot products of the equation w.x + b\n",
    "# The last value of w is b and of x is 1, so multiplied together gives b\n",
    "wxb = [[np.dot(W[i],np.transpose(X))] for i in range (3)]\n",
    "\n",
    "# Calculate the percentages. Initiate perc. Since this is out of 100, we don't have to devide. \n",
    "perc = []\n",
    "# the percentage is going to the the sum of all the elements whose mxb matches its y value. \n",
    "perc += [np.sum([((wxb[i][j] > 0) & (y[j]==1))|((wxb[i][j] < 0) & (y[j]==-1)) for j in range (len(wxb[i]))]) for i in range (3)]\n",
    "print(\"percentage for 90 iterations:\",perc[0],\"%; percentage for 100 iterations:\",perc[1],\"%; percentage for 500 iterations:\",perc[2],\"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does more steps produce a more accurate half-space model?\n",
    "With more iterations, the half-space models tends to be more accurate, but it is not a garantee, it can get worse with more iterations, but it tends to get better with more and more itterations. But I tried more iterations, and the accuracy goes up and down, so with linearly unseperable data, its not really possible to know. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Recal the logistic function discussed in class, $\\sigma(z) = \\frac{1}{1+e^{-z}}$. First, check that this function satisfies the equation $\\sigma'(z) = \\sigma(z)(1 - \\sigma(z))$. From this, verify that $\\sigma'(z) \\le \\frac1{4}$ for all $z\\in\\mathbb R$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explained on paper "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Consider a labeled data set $(\\textbf{x}_1,y_1),\\ldots,(\\textbf{x}_d, y_d)$ defined as follows. For each $1\\le i\\le d$, set $\\textbf{x}_i = \\textbf{e}_i$, the standard basis vector in $\\mathbb R^d$, and $y_i = (-1)^i$, $i=1,2,\\ldots,d$.\n",
    "* Suppose that $W^* \\in\\mathbb R^d$ is such that $y_iW^*\\cdot X_i \\ge 1$ for all $1\\le i\\le d$. Show that $|W^*|^2 \\ge d$.\n",
    "* Explain why the Perceptron algorithm will terminate after $d$ steps. What is $W$ when it terminates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explained on paper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
